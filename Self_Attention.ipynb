{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Self-Attention**\n",
        "\n",
        "\n",
        "O Self-Attention, ou autoatenção, é um mecanismo fundamental em modelos de aprendizado profundo, especialmente em tarefas de processamento de linguagem natural (PLN) e visão computacional. Ele permite que o modelo aprenda a se concentrar nas partes mais relevantes de uma entrada, como uma sequência de palavras ou uma imagem, para realizar uma tarefa específica.\n",
        "\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:856/1*ZCFSvkKtppgew3cc7BIaug.png\" width=\"400\">\n",
        "\n",
        "[Attention Is All You Need](https://arxiv.org/abs/1706.03762)"
      ],
      "metadata": {
        "id": "lYnog5i6FFra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Incorporando uma frase de entrada\n",
        "\n",
        "Considere a seguinte frase: \"A vida é curta, coma a sobremesa primeiro\" em ingles: 'Life is short, eat dessert first'"
      ],
      "metadata": {
        "id": "UwQoO7msF0R0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# criando uma incorporação da frase"
      ],
      "metadata": {
        "id": "ZZMxAp_XGtih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ar9duHN-E0nf",
        "outputId": "c7b96017-ff94-4d7e-a620-6a3327e5c056"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Life': 0, 'dessert': 1, 'eat': 2, 'first': 3, 'is': 4, 'short': 5}\n"
          ]
        }
      ],
      "source": [
        "sentence = 'Life is short, eat dessert first'\n",
        "dc = {s:i for i,s\n",
        "      in enumerate(sorted(sentence.replace(',', '').split()))}\n",
        "\n",
        "print(dc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "sentence_int = torch.tensor(\n",
        "    [dc[s] for s in sentence.replace(',', '').split()]\n",
        ")\n",
        "print(sentence_int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzLV8TjjGUD4",
        "outputId": "e2cd8859-1093-4d05-8c45-7a27b70fd03c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 4, 5, 2, 1, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usando camada embedding para codificar as entradas em uma incorporação de vetor real"
      ],
      "metadata": {
        "id": "XiaQVm0KHcvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 50_000\n",
        "\n",
        "torch.manual_seed(123)\n",
        "embed = torch.nn.Embedding(vocab_size, 3)\n",
        "embedded_sentence = embed(sentence_int).detach()\n",
        "\n",
        "print(embedded_sentence)\n",
        "print(embedded_sentence.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nE_Xs7O1G83-",
        "outputId": "252a5a2f-3022-4101-a056-f46586b1540f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.3374, -0.1778, -0.3035],\n",
            "        [ 0.1794,  1.8951,  0.4954],\n",
            "        [ 0.2692, -0.0770, -1.0205],\n",
            "        [-0.2196, -0.3792,  0.7671],\n",
            "        [-0.5880,  0.3486,  0.6603],\n",
            "        [-1.1925,  0.6984, -1.4097]])\n",
            "torch.Size([6, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6 Linhas, cada uma representando uma palavra"
      ],
      "metadata": {
        "id": "F5BXUCl4L_Fn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definindo as matrizes de pesos\n",
        "\n",
        "<img src=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fecef3e00-4c0e-4c7a-9a9f-42ac4e4ada69_366x786.png\" width=\"300\">\n",
        "\n",
        "Cada entrada retornará 3 matrizes q, k e v\n",
        "\n",
        "que são calculadas:\n",
        "\n",
        "q = x(i) * Wq\n",
        "\n",
        "k = x(i) * Wk\n",
        "\n",
        "v = x(i) * Wv\n"
      ],
      "metadata": {
        "id": "dCM721nWH29B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "d = embedded_sentence.shape[1]\n",
        "\n",
        "d_q, d_k, d_v = 2, 2, 4\n",
        "\n",
        "W_query = torch.nn.Parameter(torch.rand(d, d_q))\n",
        "W_key = torch.nn.Parameter(torch.rand(d, d_k))\n",
        "W_value = torch.nn.Parameter(torch.rand(d, d_v))"
      ],
      "metadata": {
        "id": "lQkIHLC5Hs4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculo dos pesos de atenção não normalizados\n",
        "\n",
        "Usaremos o 2° elemento de entrada como consulta\n",
        "\n",
        "<img src=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff9774001-ea9d-48bf-9857-3c911b0a279d_588x962.png\" width=\"300\">\n",
        "\n"
      ],
      "metadata": {
        "id": "_FWao6aWItnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_2 = embedded_sentence[1] # 2 entrada\n",
        "\n",
        "query_2 = x_2 @ W_query\n",
        "key_2 = x_2 @ W_key\n",
        "value_2 = x_2 @ W_value\n",
        "\n",
        "print(query_2.shape)\n",
        "print(key_2.shape)\n",
        "print(value_2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnfyIIjfIk1l",
        "outputId": "1109f446-35a9-4c8a-9c94-d8f3cf0d088a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2])\n",
            "torch.Size([2])\n",
            "torch.Size([4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generalizando para calcular a key e value restante para todas as entradas"
      ],
      "metadata": {
        "id": "j8QG1qCAJLRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keys = embedded_sentence @ W_key\n",
        "values = embedded_sentence @ W_value\n",
        "\n",
        "print(\"keys.shape:\", keys.shape)\n",
        "print(\"values.shape:\", values.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlnJ50F4JInN",
        "outputId": "ded57d2f-b40e-451e-e377-99d9f325c671"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "keys.shape: torch.Size([6, 2])\n",
            "values.shape: torch.Size([6, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculando os pesos de atenção não normalizados\n",
        "\n",
        "<img src=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbaf9e308-223b-429e-8527-a7b868003e8c_814x912.png\" width=\"400\">"
      ],
      "metadata": {
        "id": "c-TMkCjbJ7BQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "omega_24 = query_2.dot(keys[4])\n",
        "print(omega_24)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwc933ytJ0Qs",
        "outputId": "6f598749-9705-4e89-aef1-2c3855cc1ca9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.2903, grad_fn=<DotBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "omega_2 = query_2 @ keys.T\n",
        "print(omega_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsSwStxnKi5Z",
        "outputId": "e5bf8072-fc1d-491a-a33b-ffe017f3439b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.6004,  3.4707, -1.5023,  0.4991,  1.2903, -1.3374],\n",
            "       grad_fn=<SqueezeBackward4>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalizando os pesos de atenção\n",
        "\n",
        "<img src=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F42da287a-18e8-45c7-860c-46e8a3a534fc_1400x798.png\" width=\"700\">"
      ],
      "metadata": {
        "id": "4d_dQHLkKvS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "attention_weights_2 = F.softmax(omega_2 / d_k**0.5, dim=0)\n",
        "print(attention_weights_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCa0n-5sKhzd",
        "outputId": "105ef3d7-dc78-427b-9da0-256e2b8b3c86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0386, 0.6870, 0.0204, 0.0840, 0.1470, 0.0229],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculando o Vetor de Contexto\n",
        "\n",
        "<img src=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6e1dcdeb-e096-4ff9-bdf9-3338e4efa4b4_1916x1048.png\" width=\"700\">"
      ],
      "metadata": {
        "id": "J1cgAnsPLE1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context_vector_2 = attention_weights_2 @ values\n",
        "print(context_vector_2.shape)\n",
        "print(context_vector_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8fQusvGLAcs",
        "outputId": "c81bb634-c3ba-4d6a-94ad-5e97c87348ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4])\n",
            "tensor([0.5313, 1.3607, 0.7891, 1.3110], grad_fn=<SqueezeBackward4>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resumindo a self-attention em uma classe compacta"
      ],
      "metadata": {
        "id": "TvbE30OyLXia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, d_in, d_out_kq, d_out_v):\n",
        "        super().__init__()\n",
        "        self.d_out_kq = d_out_kq\n",
        "        self.W_query = nn.Parameter(torch.rand(d_in, d_out_kq))\n",
        "        self.W_key   = nn.Parameter(torch.rand(d_in, d_out_kq))\n",
        "        self.W_value = nn.Parameter(torch.rand(d_in, d_out_v))\n",
        "\n",
        "    def forward(self, x):\n",
        "        keys = x @ self.W_key\n",
        "        queries = x @ self.W_query\n",
        "        values = x @ self.W_value\n",
        "\n",
        "        attn_scores = queries @ keys.T  # unnormalized attention weights\n",
        "        attn_weights = torch.softmax(\n",
        "            attn_scores / self.d_out_kq**0.5, dim=-1\n",
        "        )\n",
        "\n",
        "        context_vec = attn_weights @ values\n",
        "        return context_vec"
      ],
      "metadata": {
        "id": "1DuI-UYGLHUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "# reduza d_out_v de 4 para 1, porque temos 4 heads\n",
        "d_in, d_out_kq, d_out_v = 3, 2, 4\n",
        "\n",
        "sa = SelfAttention(d_in, d_out_kq, d_out_v)\n",
        "print(sa(embedded_sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzoGwqP5LeQV",
        "outputId": "554f7409-cfd2-40b5-ad20-33c6c6419067"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1564,  0.1028, -0.0763, -0.0764],\n",
            "        [ 0.5313,  1.3607,  0.7891,  1.3110],\n",
            "        [-0.3542, -0.1234, -0.2626, -0.3706],\n",
            "        [ 0.0071,  0.3345,  0.0969,  0.1998],\n",
            "        [ 0.1008,  0.4780,  0.2021,  0.3674],\n",
            "        [-0.5296, -0.2799, -0.4107, -0.6006]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qzjU05hcLkDF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}